{
    "coefficients": [
        -1.4767645485957221,
        7.286389742388021,
        0.8170882470260915,
        -0.019774403494211175,
        1.4515123984071112,
        -2.2176660282029266
    ],
    "intercept": -242.77666141936805,
    "features": [
        "w_gpu_percent",
        "w_cpu_percent",
        "cache_gpu_percent * batch_size",
        "cache_cpu_percent * batch_size",
        "batch_size",
        "log(batch_size)"
    ],
    "mse": 2.7612955819589984,
    "equation": "inference_latency = -1.4768 * w_gpu_percent + 7.2864 * w_cpu_percent + 0.8171 * cache_gpu_percent * batch_size + -0.0198 * cache_cpu_percent * batch_size + 1.4515 * batch_size + -2.2177 * log(batch_size) + -242.7767"
}