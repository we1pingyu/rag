{
    "coefficients": [
        0.240132742696212,
        0.09365209798934686,
        0.010543310162678494,
        -0.005263146068097268,
        0.8642914901196493,
        3.8996311376673463
    ],
    "intercept": 17.39762967912094,
    "features": [
        "w_gpu_percent",
        "w_cpu_percent",
        "cache_gpu_percent * batch_size",
        "cache_cpu_percent * batch_size",
        "batch_size",
        "log(batch_size)"
    ],
    "mse": 10.628623473263794,
    "equation": "inference_latency = 0.2401 * w_gpu_percent + 0.0937 * w_cpu_percent + 0.0105 * cache_gpu_percent * batch_size + -0.0053 * cache_cpu_percent * batch_size + 0.8643 * batch_size + 3.8996 * log(batch_size) + 17.3976"
}