{
    "coefficients": [
        2.9891928250380384,
        -3.2051284838076803,
        -4.440892098500626e-16,
        0.03168974331332704,
        -1.7816465311216156,
        -3.212657048658095
    ],
    "intercept": 96.74968664094729,
    "features": [
        "w_gpu_percent",
        "w_cpu_percent",
        "cache_gpu_percent * batch_size",
        "cache_cpu_percent * batch_size",
        "batch_size",
        "log(batch_size)"
    ],
    "mse": 13.065119453171015,
    "equation": "inference_latency = 2.9892 * w_gpu_percent + -3.2051 * w_cpu_percent + -0.0000 * cache_gpu_percent * batch_size + 0.0317 * cache_cpu_percent * batch_size + -1.7816 * batch_size + -3.2127 * log(batch_size) + 96.7497"
}